{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "744c3b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import deque\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df3d17",
   "metadata": {},
   "source": [
    "### Load and Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9da6e1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.read_csv(\"../../data/raw/twitter/german/GermanyMdBTweets_2023.csv\")\n",
    "df_replies = pd.read_csv(\"../../data/raw/twitter/german/GermanyReplies2023.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64285c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = defaultdict(list)\n",
    "\n",
    "for id, tweet in df_tweets.iterrows():\n",
    "    tweet_dict = {\n",
    "        # Tweet and Reply metadata\n",
    "        'id': str(tweet['id']),\n",
    "        'text': tweet['text'],\n",
    "        'author_id': str(tweet['author_id']),\n",
    "        'created_at': tweet['created_at'],\n",
    "\n",
    "        # Tweet metadata\n",
    "        \"username\": tweet['username']\n",
    "    }\n",
    "    \n",
    "    # Append the tweet to the corresponding conversation\n",
    "    conversation[tweet[\"conversation_id\"]].append(tweet_dict)\n",
    "\n",
    "for id, tweet in df_replies.iterrows():\n",
    "    tweet_dict = {\n",
    "        # Tweet and Reply metadata\n",
    "        'id': str(tweet['id']),\n",
    "        'text': tweet['text'],\n",
    "        'author_id': str(tweet['author_id']),\n",
    "        'created_at': tweet['created_at'],\n",
    "\n",
    "        # Reply metadata\n",
    "        'in_reply_to_user_id': str(tweet['in_reply_to_user_id'])\n",
    "    }\n",
    "    \n",
    "    # Append the tweet to the corresponding conversation\n",
    "    conversation[tweet[\"conversation_id\"]].append(tweet_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0410204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through dict and sort each list by created_at with the earliest first\n",
    "for conv_id, tweets in conversation.items():\n",
    "    conversation[conv_id] = sorted(tweets, key=lambda x: x['created_at'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1624aec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_replies = defaultdict(list)\n",
    "\n",
    "for conv_id, tweets in conversation.items():\n",
    "\n",
    "    if len(tweets) < 2:\n",
    "        #print(f\"Skipping conversation {tweets} because it has no matched replies\")\n",
    "        continue\n",
    "\n",
    "    if tweets[0].get(\"in_reply_to_user_id\", None) is not None:\n",
    "        #print(f\"Skipping conversation {tweets} because the first tweet is a reply\")\n",
    "        continue\n",
    "\n",
    "    for tweet in tweets[1:]:\n",
    "\n",
    "        tweet[\"conversation_id\"] = conv_id\n",
    "\n",
    "        if tweet.get(\"in_reply_to_user_id\", None) is None:\n",
    "            #print(f\"Skipping tweet {tweet} because it is not a reply\")\n",
    "            continue\n",
    "\n",
    "        if tweet[\"in_reply_to_user_id\"] != tweets[0][\"author_id\"]:\n",
    "            #print(f\"Skipping tweet {tweet} because it is not a reply to the first tweet\")\n",
    "            continue\n",
    "        \n",
    "\n",
    "        if tweet[\"conversation_id\"] in [r[1][\"conversation_id\"] for r in individual_replies[tweet[\"author_id\"]]]:\n",
    "            #print(f\"Skipping tweet {tweet} because it is a duplicate reply or the user has already replied to the first tweet\")\n",
    "            continue\n",
    "\n",
    "        individual_replies[tweet[\"author_id\"]].append((tweets[0], tweet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45700f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replies = pd.DataFrame([\n",
    "    {\n",
    "        'reply_id': reply[1]['id'],\n",
    "        'reply': reply[1]['text'],\n",
    "        'reply_author_id': reply[1]['author_id'],\n",
    "        'reply_created_at': reply[1]['created_at'],\n",
    "        \"reply_to_user_id\": reply[1]['in_reply_to_user_id'],\n",
    "\n",
    "        'base_id': reply[0]['id'],\n",
    "        \"base_username\": reply[0]['username'],\n",
    "        'base_author_id': reply[0]['author_id'],\n",
    "        'base_text': reply[0]['text']\n",
    "    }\n",
    "    for replies in individual_replies.values() for reply in replies\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbc24a8",
   "metadata": {},
   "source": [
    "### Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d73b49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 replies\n"
     ]
    }
   ],
   "source": [
    "# Catch cases where reply is not to the original author\n",
    "len_before = len(df_replies)\n",
    "df_replies = df_replies[df_replies[\"reply_to_user_id\"] == df_replies[\"base_author_id\"]]\n",
    "len_after = len(df_replies)\n",
    "print(f\"Removed {len_before - len_after} replies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e933b4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 29304 replies\n"
     ]
    }
   ],
   "source": [
    "# delete any row where base_text starts with an @ because it's a reply\n",
    "length_before = len(df_replies)\n",
    "df_replies = df_replies[~df_replies[\"base_text\"].str.startswith(\"@\", na=False)]\n",
    "length_after = len(df_replies)\n",
    "print(f\"Removed {length_before - length_after} replies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b126df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 2104371 rows containing URLs\n"
     ]
    }
   ],
   "source": [
    "# delete any row where either reply or in_reply_to_text contains an url\n",
    "length_before = len(df_replies)\n",
    "df_replies = df_replies[~df_replies[\"reply\"].str.contains(\"http|www|https\", na=False)]\n",
    "df_replies = df_replies[~df_replies[\"base_text\"].str.contains(\"http|www|https\", na=False)]\n",
    "length_after = len(df_replies)\n",
    "print(f\"Removed {length_before - length_after} rows containing URLs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac470057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 5912 duplicate replies\n"
     ]
    }
   ],
   "source": [
    "# Delete any duplicate replies\n",
    "length_before = len(df_replies)\n",
    "df_replies = df_replies.drop_duplicates(subset=[\"reply\", \"base_text\"], keep=\"first\")\n",
    "length_after = len(df_replies)\n",
    "print(f\"Removed {length_before - length_after} duplicate replies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41dbbc24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicate replies\n"
     ]
    }
   ],
   "source": [
    "# Delete any duplicate replies\n",
    "length_before = len(df_replies)\n",
    "df_replies = df_replies.drop_duplicates(subset=[\"reply_id\"], keep=\"first\")\n",
    "length_after = len(df_replies)\n",
    "print(f\"Removed {length_before - length_after} duplicate replies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2243329e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replies[\"reply_author_id\"] = df_replies[\"reply_author_id\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "65d27a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 117252 replies from users in the top 5% of reply counts\n"
     ]
    }
   ],
   "source": [
    "# remove users in the top 5% of reply counts\n",
    "length_before = len(df_replies)\n",
    "top_5_percent_users = df_replies[\"reply_author_id\"].value_counts().quantile(0.99)\n",
    "df_replies = df_replies[~df_replies[\"reply_author_id\"].isin(df_replies[\"reply_author_id\"].value_counts()[df_replies[\"reply_author_id\"].value_counts() >= top_5_percent_users].index)]\n",
    "length_after = len(df_replies)\n",
    "print(f\"Removed {length_before - length_after} replies from users in the top 5% of reply counts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "70fa0b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 76559 users with less than 3 conversations\n"
     ]
    }
   ],
   "source": [
    "# drop users with less than 4 conversations because we require at least 3 demonstrations and 1 for actual training/fitting\n",
    "length = [len(df_replies[df_replies[\"reply_author_id\"] == reply_author_id]) for reply_author_id in df_replies[\"reply_author_id\"].unique()]\n",
    "\n",
    "authors_to_keep = df_replies[\"reply_author_id\"].value_counts()[df_replies[\"reply_author_id\"].value_counts() >= 4].index\n",
    "df_replies = df_replies[df_replies[\"reply_author_id\"].isin(authors_to_keep)]\n",
    "\n",
    "print(f'Dropped {len(length) - len(df_replies[\"reply_author_id\"].unique())} users with less than 3 conversations')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bf1ba4",
   "metadata": {},
   "source": [
    "### Generate Train & Testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69ca2bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_replies[\"prompt\"] = \">\" + df_replies[\"base_username\"] + \": \" + df_replies[\"base_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "74eb0f78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reply_author_id\n",
       "3334280543             62\n",
       "176557293              62\n",
       "21647895               62\n",
       "930772154232262656     62\n",
       "1562669284920213505    62\n",
       "                       ..\n",
       "1218117719532494848     4\n",
       "100525691               4\n",
       "1590278150021419009     4\n",
       "288627622               4\n",
       "952236980120838145      4\n",
       "Name: count, Length: 39604, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_replies[\"reply_author_id\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b5c3f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# randomly sample 15% of the users as test users\n",
    "test_users = df_replies[\"reply_author_id\"].unique()\n",
    "test_users = np.random.choice(test_users, size=int(len(test_users) * 0.15), replace=False)\n",
    "\n",
    "# create test and train df\n",
    "train_df = df_replies[~df_replies[\"reply_author_id\"].isin(test_users)]\n",
    "test_df = df_replies[df_replies[\"reply_author_id\"].isin(test_users)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cb9868e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing train data: 100%|██████████| 33664/33664 [00:04<00:00, 6760.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 33664 training examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing evaluation data: 100%|██████████| 5940/5940 [00:00<00:00, 57503.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 5940 evaluation examples\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create n-shot demonstrations separately for train and test sets\n",
    "def create_n_shot_examples(source_df, n_shots=3, name=\"train\"):\n",
    "    # Organize conversational data by discourse participant\n",
    "    author_conversations = defaultdict(list)\n",
    "    for _, row in source_df.iterrows():\n",
    "        author = row['reply_author_id']\n",
    "        conversation = row['prompt']\n",
    "        reply = row['reply']\n",
    "        timestamp = row['reply_created_at']\n",
    "        author_conversations[author].append({\n",
    "            \"conversation\": conversation,\n",
    "            \"reply\": reply,\n",
    "            \"timestamp\": timestamp\n",
    "        })\n",
    "\n",
    "    # Generate structured conversational instances with n-shot demonstrations\n",
    "    training_instances = []\n",
    "\n",
    "    for author, conversations in tqdm(author_conversations.items(), desc=f\"Processing {name} data\"):\n",
    "            conversations.sort(key=lambda x: x['timestamp'])\n",
    "            conversations = conversations[-n_shots:]\n",
    "            messages = []\n",
    "            \n",
    "            for i in range(len(conversations)):\n",
    "                messages.append({\"role\": \"user\", \"content\": conversations[i]['conversation']})\n",
    "                messages.append({\"role\": \"assistant\", \"content\": conversations[i]['reply']})\n",
    "\n",
    "            training_instances.append({\n",
    "                    \"messages\": messages,\n",
    "            })\n",
    "    \n",
    "    return training_instances\n",
    "\n",
    "\n",
    "for n in [30]:\n",
    "    # Generate training data from the pre-existing train/test split\n",
    "    n_shots = n  # Parameterizable based on experimental requirements\n",
    "    \n",
    "    # Generate train data\n",
    "    train_data = create_n_shot_examples(train_df, n_shots=n_shots, name=\"train\")\n",
    "    print(f\"Generated {len(train_data)} training examples\")\n",
    "\n",
    "    # Generate evaluation data\n",
    "    test_data = create_n_shot_examples(test_df, n_shots=n_shots, name=\"evaluation\")\n",
    "    print(f\"Generated {len(test_data)} evaluation examples\")\n",
    "\n",
    "\n",
    "    # Save the data to files\n",
    "    with open(f'../../data/intermediate/ger_{n_shots}-shot_train.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(train_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    with open(f'../../data/intermediate/ger_{n_shots}-shot_test.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(test_data, f, ensure_ascii=False, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "echo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
